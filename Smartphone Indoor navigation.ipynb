{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "geojson_map=[]\n",
    "floor_image=[]\n",
    "floor_info=[]\n",
    "\n",
    "train=[]\n",
    "test=[]\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "         \n",
    "        if \"metadata\" in os.path.join(dirname, filename):\n",
    "            if os.path.join(dirname, filename).endswith(\"geojson_map.json\"):\n",
    "                geojson_map.append(os.path.join(dirname, filename))\n",
    "            elif os.path.join(dirname, filename).endswith(\"floor_image.png\"):\n",
    "                floor_image.append(os.path.join(dirname, filename))\n",
    "            elif os.path.join(dirname, filename).endswith(\"floor_info.json\"):\n",
    "                floor_info.append(os.path.join(dirname, filename))\n",
    "        elif \"train\" in os.path.join(dirname, filename):\n",
    "            if os.path.join(dirname, filename).endswith(\".txt\"):\n",
    "                train.append(os.path.join(dirname, filename))\n",
    "        elif \"test\" in os.path.join(dirname, filename):\n",
    "            test.append(os.path.join(dirname, filename))\n",
    "        else:\n",
    "            print(os.path.join(dirname, filename))\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "#Metadata part can be looked later on.\n",
    "img = mpimg.imread('/kaggle/input/indoor-location-navigation/metadata/5cd56c0ce2acfd2d33b6ab27/B1/floor_image.png')  \n",
    "GEOpre=pd.read_json('/kaggle/input/indoor-location-navigation/metadata/5cd56c0ce2acfd2d33b6ab27/B1/geojson_map.json')\n",
    "geo=pd.json_normalize(GEOpre[\"features\"])\n",
    "floor=pd.read_json(\"/kaggle/input/indoor-location-navigation/metadata/5cd56c0ce2acfd2d33b6ab27/B1/floor_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "Floors = {\"B2\": -2, \"B1\": -1, \"F1\": 0, \"F2\": 1, \"F3\": 2, \"F4\": 3, \"F5\": 4, \"F6\": 5, \"F7\": 6, \"F8\": 7, \"F9\": 8,\"1F\": 0, \"2F\": 1, \"3F\": 2, \"4F\": 3, \"5F\": 4, \"6F\": 5, \"7F\": 6, \"8F\": 7, \"9F\": 8}\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "def repair(path):\n",
    "    file1 = open(path, 'r')\n",
    "    Lines = file1.readlines()\n",
    "    updated=[]\n",
    "    for line in Lines:\n",
    "        if 2<=line.strip().count(\"TYPE_\"):\n",
    "            ID=[]\n",
    "            for a in re.finditer(r\"(?=15.{12,}TYPE_)\",line):\n",
    "                ID.append(a.start(0))  \n",
    "            for sub in range(len(ID)):\n",
    "                if sub!=len(ID)-1:\n",
    "                    updated.append(line[ID[sub]:ID[sub+1]]+\"\\n\")\n",
    "                else:\n",
    "                    updated.append(line[ID[sub]:])\n",
    "        else:\n",
    "            updated.append(line)\n",
    "    with open('/kaggle/working/5cf765ece23e6e000833f03b.txt', 'w') as f:\n",
    "        for item in updated:\n",
    "            f.write(\"%s\" % item)\n",
    "    names = ['Time', 'Type'] + ['Feature_'+str(x) for x in range(1,9)]\n",
    "    df = pd.read_csv('/kaggle/working/5cf765ece23e6e000833f03b.txt', sep='\\t', comment='#', header=None, names=names, low_memory=False)\n",
    "    return df\n",
    "\n",
    "def genereateXY(row,row2):\n",
    "\n",
    "    Time=row[0]\n",
    "    X=row[1]\n",
    "    Y=row[2]\n",
    "    Time2=row2[0]\n",
    "    X2=row2[1]\n",
    "    Y2=row2[2]\n",
    "\n",
    "    t=Time2-Time\n",
    "    X=float(X)\n",
    "    X2=float(X2)\n",
    "    Y=float(Y)\n",
    "    Y2=float(Y2)\n",
    "    All=[]\n",
    "    for c in range(t):\n",
    "\n",
    "        VX=(X2-X)/t\n",
    "        VY=(Y2-Y)/t\n",
    "\n",
    "        NX=VX*c+X\n",
    "        NY=VY*c+Y\n",
    "\n",
    "        All.append([Time+c,NX,NY])\n",
    "    return All\n",
    "\n",
    "\n",
    "def train_DT(path_trace):\n",
    "    try:   \n",
    "        names = ['Time', 'Type'] + ['Feature_'+str(x) for x in range(1,9)]\n",
    "        df = pd.read_csv(path_trace, sep='\\t', comment='#', header=None, names=names, low_memory=False)\n",
    "        Floor=Floors[path_trace.split(\"/\")[-2]]\n",
    "        ListXYZ=[]\n",
    "        ListXYZXYZ=[]\n",
    "        for a in df[\"Type\"].unique():\n",
    "            if a in [\"TYPE_ACCELEROMETER\",\"TYPE_MAGNETIC_FIELD\",\"TYPE_GYROSCOPE\",\"TYPE_ROTATION_VECTOR\"]:\n",
    "                a=df[df[\"Type\"]==str(a)][[\"Time\",\"Feature_1\",\"Feature_2\",\"Feature_3\"]].rename(columns={\"Feature_1\":str(a)+\"_X\",\"Feature_2\":str(a)+\"_Y\",\"Feature_3\":str(a)+\"_Z\"})\n",
    "                ListXYZ.append(a)\n",
    "            elif  a in [\"TYPE_GYROSCOPE_UNCALIBRATED\",\"TYPE_MAGNETIC_FIELD_UNCALIBRATED\",\"TYPE_ACCELEROMETER_UNCALIBRATED\"]:\n",
    "                a=df[df[\"Type\"]==str(a)][[\"Time\",\"Feature_1\",\"Feature_2\",\"Feature_3\",\"Feature_4\",\"Feature_5\",\"Feature_6\"]].rename(columns={\"Feature_1\":str(a)+\"_X\",\"Feature_2\":str(a)+\"_Y\",\"Feature_3\":str(a)+\"_Z\",\"Feature_4\":str(a)+\"_X2\",\"Feature_5\":str(a)+\"_Y2\",\"Feature_6\":str(a)+\"_Z2\"})\n",
    "\n",
    "                ListXYZXYZ.append(a)\n",
    "\n",
    "        TYPE_WAYPOINT=df[df[\"Type\"]==\"TYPE_WAYPOINT\"][[\"Time\",\"Feature_1\",\"Feature_2\"]].rename(columns={\"Feature_1\":\"X\",\"Feature_2\":\"Y\"})        \n",
    "        TYPE_ACCELEROMETER=ListXYZ[0]\n",
    "        TYPE_MAGNETIC_FIELD=ListXYZ[1]\n",
    "        TYPE_GYROSCOPE=ListXYZ[2]\n",
    "        TYPE_ROTATION_VECTOR=ListXYZ[3]\n",
    "        TYPE_MAGNETIC_FIELD_UNCALIBRATED =ListXYZXYZ[0]\n",
    "        TYPE_GYROSCOPE_UNCALIBRATED=ListXYZXYZ[1]\n",
    "        TYPE_ACCELEROMETER_UNCALIBRATED=ListXYZXYZ[2]\n",
    "        TYPE_WIFI=df[df[\"Type\"]==\"TYPE_WIFI\"][[\"Time\",\"Feature_1\",\"Feature_2\",\"Feature_3\",\"Feature_4\",\"Feature_5\"]].rename(columns={\"Feature_1\":\"ssid\",\"Feature_2\":\"bssid\",\"Feature_3\":\"RSSI\",\"Feature_4\":\"frequency\",\"Feature_5\":\"last seen timestamp\"})\n",
    "        TYPE_BEACON=df[df[\"Type\"]==\"TYPE_BEACON\"][[\"Time\",\"Feature_1\",\"Feature_2\",\"Feature_3\",\"Feature_4\",\"Feature_5\",\"Feature_6\",\"Feature_7\",\"Feature_8\"]].rename(columns={\"Feature_1\":\"UUID\",\"Feature_2\":\"MajorID\",\"Feature_3\":\"MinorID\",\"Feature_4\":\"Tx Power\",\"Feature_5\":\"RSSI\",\"Feature_6\":\"Distance\",\"Feature_7\":\"MAC Address\",\"Feature_8\":\"padding data\"})\n",
    "\n",
    "\n",
    "\n",
    "        AXX=TYPE_ROTATION_VECTOR.merge(TYPE_GYROSCOPE.merge(TYPE_ACCELEROMETER.merge(TYPE_MAGNETIC_FIELD,on='Time'),on='Time'),on='Time')\n",
    "        expected=pd.DataFrame(genereateXY(TYPE_WAYPOINT.iloc[0].values,TYPE_WAYPOINT.iloc[1].values),columns=[\"Time\",\"X_expected\",\"Y_expected\"])\n",
    "        ALL=AXX.merge(expected,how=\"inner\",on=\"Time\")\n",
    "        Inp=ALL[[\"TYPE_ROTATION_VECTOR_X\",\"TYPE_ROTATION_VECTOR_Y\",\"TYPE_ROTATION_VECTOR_Z\",\"TYPE_GYROSCOPE_X\",\"TYPE_GYROSCOPE_Y\",\"TYPE_GYROSCOPE_Z\",\"TYPE_ACCELEROMETER_X\",\"TYPE_ACCELEROMETER_Y\",\"TYPE_ACCELEROMETER_Z\",\"TYPE_MAGNETIC_FIELD_X\",\"TYPE_MAGNETIC_FIELD_Y\",\"TYPE_MAGNETIC_FIELD_Z\"]]\n",
    "        Output=ALL[[\"X_expected\",\"Y_expected\"]]\n",
    "        Output[\"Floor\"]=np.ones_like(Output[\"X_expected\"])*Floor\n",
    "        return Inp,Output\n",
    "    except:\n",
    "        df=repair(path_trace)\n",
    "        \n",
    "        Floor=Floors[path_trace.split(\"/\")[-2]]\n",
    "\n",
    "\n",
    "        ListXYZ=[]\n",
    "        ListXYZXYZ=[]\n",
    "        for a in df[\"Type\"].unique():\n",
    "            if a in [\"TYPE_ACCELEROMETER\",\"TYPE_MAGNETIC_FIELD\",\"TYPE_GYROSCOPE\",\"TYPE_ROTATION_VECTOR\"]:\n",
    "                a=df[df[\"Type\"]==str(a)][[\"Time\",\"Feature_1\",\"Feature_2\",\"Feature_3\"]].rename(columns={\"Feature_1\":str(a)+\"_X\",\"Feature_2\":str(a)+\"_Y\",\"Feature_3\":str(a)+\"_Z\"})\n",
    "                ListXYZ.append(a)\n",
    "            elif  a in [\"TYPE_GYROSCOPE_UNCALIBRATED\",\"TYPE_MAGNETIC_FIELD_UNCALIBRATED\",\"TYPE_ACCELEROMETER_UNCALIBRATED\"]:\n",
    "                a=df[df[\"Type\"]==str(a)][[\"Time\",\"Feature_1\",\"Feature_2\",\"Feature_3\",\"Feature_4\",\"Feature_5\",\"Feature_6\"]].rename(columns={\"Feature_1\":str(a)+\"_X\",\"Feature_2\":str(a)+\"_Y\",\"Feature_3\":str(a)+\"_Z\",\"Feature_4\":str(a)+\"_X2\",\"Feature_5\":str(a)+\"_Y2\",\"Feature_6\":str(a)+\"_Z2\"})\n",
    "\n",
    "                ListXYZXYZ.append(a)\n",
    "\n",
    "        TYPE_WAYPOINT=df[df[\"Type\"]==\"TYPE_WAYPOINT\"][[\"Time\",\"Feature_1\",\"Feature_2\"]].rename(columns={\"Feature_1\":\"X\",\"Feature_2\":\"Y\"})        \n",
    "        TYPE_ACCELEROMETER=ListXYZ[0]\n",
    "        TYPE_MAGNETIC_FIELD=ListXYZ[1]\n",
    "        TYPE_GYROSCOPE=ListXYZ[2]\n",
    "        TYPE_ROTATION_VECTOR=ListXYZ[3]\n",
    "        TYPE_MAGNETIC_FIELD_UNCALIBRATED =ListXYZXYZ[0]\n",
    "        TYPE_GYROSCOPE_UNCALIBRATED=ListXYZXYZ[1]\n",
    "        TYPE_ACCELEROMETER_UNCALIBRATED=ListXYZXYZ[2]\n",
    "        TYPE_WIFI=df[df[\"Type\"]==\"TYPE_WIFI\"][[\"Time\",\"Feature_1\",\"Feature_2\",\"Feature_3\",\"Feature_4\",\"Feature_5\"]].rename(columns={\"Feature_1\":\"ssid\",\"Feature_2\":\"bssid\",\"Feature_3\":\"RSSI\",\"Feature_4\":\"frequency\",\"Feature_5\":\"last seen timestamp\"})\n",
    "        TYPE_BEACON=df[df[\"Type\"]==\"TYPE_BEACON\"][[\"Time\",\"Feature_1\",\"Feature_2\",\"Feature_3\",\"Feature_4\",\"Feature_5\",\"Feature_6\",\"Feature_7\",\"Feature_8\"]].rename(columns={\"Feature_1\":\"UUID\",\"Feature_2\":\"MajorID\",\"Feature_3\":\"MinorID\",\"Feature_4\":\"Tx Power\",\"Feature_5\":\"RSSI\",\"Feature_6\":\"Distance\",\"Feature_7\":\"MAC Address\",\"Feature_8\":\"padding data\"})\n",
    "\n",
    "\n",
    "\n",
    "        AXX=TYPE_ROTATION_VECTOR.merge(TYPE_GYROSCOPE.merge(TYPE_ACCELEROMETER.merge(TYPE_MAGNETIC_FIELD,on='Time'),on='Time'),on='Time')\n",
    "        expected=pd.DataFrame(genereateXY(TYPE_WAYPOINT.iloc[0].values,TYPE_WAYPOINT.iloc[1].values),columns=[\"Time\",\"X_expected\",\"Y_expected\"])\n",
    "        ALL=AXX.merge(expected,how=\"inner\",on=\"Time\")\n",
    "        Inp=ALL[[\"TYPE_ROTATION_VECTOR_X\",\"TYPE_ROTATION_VECTOR_Y\",\"TYPE_ROTATION_VECTOR_Z\",\"TYPE_GYROSCOPE_X\",\"TYPE_GYROSCOPE_Y\",\"TYPE_GYROSCOPE_Z\",\"TYPE_ACCELEROMETER_X\",\"TYPE_ACCELEROMETER_Y\",\"TYPE_ACCELEROMETER_Z\",\"TYPE_MAGNETIC_FIELD_X\",\"TYPE_MAGNETIC_FIELD_Y\",\"TYPE_MAGNETIC_FIELD_Z\"]]\n",
    "        Output=ALL[[\"X_expected\",\"Y_expected\"]]\n",
    "        Output[\"Floor\"]=np.ones_like(Output[\"X_expected\"])*Floor\n",
    "        return Inp,Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "pd.options.mode.chained_assignment = None\n",
    "clf = GradientBoostingRegressor(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "wrapper = MultiOutputRegressor(clf)\n",
    "def counting():\n",
    "    count=0\n",
    "    for a in train[0:50]:\n",
    "        Inp,Output=train_DT(a)\n",
    "        wrapper.fit(Inp,Output)\n",
    "        count=count+1\n",
    "    return count,len(train[:50])\n",
    "counting()\n",
    "\n",
    "\n",
    "################# Hasn^'t finished yet ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file1 = open('/kaggle/input/indoor-location-navigation/train/5cd56ba1e2acfd2d33b603af/F1/5cf765ece23e6e000833f03b.txt', 'r')# A sample path\n",
    "# Lines = file1.readlines()\n",
    "# for line in Lines:\n",
    "#     if 2==line.strip().count(\"TYPE_\"):\n",
    "#         print(\"orginal:\",line)\n",
    "#         ID=[]\n",
    "#         for a in re.finditer(r\"(?=15............TYPE_)\",line):\n",
    "#             ID.append(a.start(0))\n",
    "#         print(\"ordered---------*****\")\n",
    "#         print(\"First:\",line[0:ID[1]])\n",
    "#         print(\"Second:\",line[ID[1]:])\n",
    "#         print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
